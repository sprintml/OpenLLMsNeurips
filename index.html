<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <!-- Meta tags for social media banners, these should be filled in appropriatly as they are your "business card" -->
  <!-- Replace the content tag with appropriate information -->
  <meta name="description" content="Project page for our NeurIPS 2024 paper Open LLMs are Necessary for Current Private Adaptations and Outperform their Closed Alternatives">
  <meta property="og:title" content="Open LLMs are Necessary for Private Adaptations"/>
  <meta property="og:description" content="Open LLMs are Necessary for Current Private Adaptations and Outperform their Closed Alternatives (NeurIPS 2024)"/>
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X630-->
  <meta property="og:image" content="static/image/your_banner_image.png" />
  <meta property="og:image:width" content="1200"/>
  <meta property="og:image:height" content="630"/>

  <!-- Keywords for your paper to be indexed by-->
  <meta name="keywords" content="LLM, privacy, differential privacy, dp-sgd, private fine-tuning, in-context learning">
  <meta name="viewport" content="width=device-width, initial-scale=1">


  <title>Open LLMs are Necessary for Private Adaptations</title>
  <link rel="icon" type="image/x-icon" href="static/images/favicon.ico">
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
  rel="stylesheet">

  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
  href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script src="static/js/bulma-carousel.min.js"></script>
  <script src="static/js/bulma-slider.min.js"></script>
  <script src="static/js/index.js"></script>
</head>
<body>


  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-1 publication-title">Open LLMs are Necessary for Current Private Adaptations and Outperform their Closed Alternatives</h1>
            <img src="static/images/NeurIPS-logo.svg" alt="NeurIPS" style="width:40%;"/>
            <div class="is-size-5 publication-authors">
              <!-- Paper authors -->
              <span class="author-block">
                <a href="https://sprintml.com/" target="_blank">Vincent Hanke</a>,
              </span>
                <span class="author-block">
                  <a href="https://sprintml.com/" target="_blank">Tom Blanchard</a>,
                </span>
                  <span class="author-block">
                    <a href="https://iyempissy.github.io/" target="_blank">Iyiola Emmanuel Olatunji</a>,
                  </span>
                  <span class="author-block">
                    <a href="https://franziska-boenisch.de/" target="_blank">Franziska Boenisch</a>
                  </span>
                  <span class="author-block">
                    <a href="https://michaelbackes.eu/" target="_blank">Michael Backes</a>,
                  </span>
                  <span class="author-block">
                    <a href="https://adam-dziedzic.com/" target="_blank">Adam Dziedzic</a>,
                  </span>
                  </div>

                  <div class="is-size-5 publication-authors">
                    <span class="author-block">CISPA Helmholtz Center for Information Security<br></span>
                  </div>
                  <div class="column has-text-centered">
                    <div class="publication-links">
                         <!-- Arxiv PDF link -->
                      <span class="link-block">
                        <a href="https://arxiv.org/pdf/2411.05818" target="_blank"
                        class="external-link button is-normal is-rounded is-dark">
                        <span class="icon">
                          <i class="fas fa-file-pdf"></i>
                        </span>
                        <span>Paper</span>
                      </a>
                    </span>

                <!-- ArXiv abstract Link -->
                <span class="link-block">
                  <a href="https://arxiv.org/abs/2411.05818" target="_blank"
                  class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                    <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>



<!-- Paper Key Takeaways -->
<section class="section hero is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
        <div class="content has-text-justified">
          <p>
            <b>Poster Location</b><br>
            East Exhibit Hall A-C #2204 <br> Thu 12 Dec 4:30 p.m. PST — 7:30 p.m.
          </p>
        </div>
    </div>
  </div>
</section>
<!-- End paper Key Takeaways -->



<!-- Teaser video-->
<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <figure><img src="static/images/adam_openLLMs.png" alt="Advantages Open LLMs" style="width:100%;" class="center"/></figure>
           
      <h2 class="subtitle has-text-centered">
        <b>TL;DR:</b> We compared private adaptations for open vs. closed LLMs on multiple axes and found that by adapting open LLMs instead of closed ones, we can preserve more privacy and obtain higher performance at lower cost. On the way, we also designed novel private prompting methods for generative tasks. 
      </h2>
    </div>
  </div>
</section>
<!-- End teaser video -->

<!-- Paper abstract -->
<section class="section hero is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            While open Large Language Models (LLMs) have made significant progress, they
            still fall short of matching the performance of their closed, proprietary counterparts,
            making the latter attractive even for the use on highly private data. Recently,
            various new methods have been proposed to adapt closed LLMs to private data
            without leaking private information to third parties and/or the LLM provider. In
            this work, we analyze the privacy protection and performance of the four most
            recent methods for private adaptation of closed LLMs. By examining their threat
            models and thoroughly comparing their performance under different privacy levels
            according to differential privacy (DP), various LLM architectures, and multiple
            datasets for classification and generation tasks, we find that: (1) all the methods
            leak query data, i.e., the (potentially sensitive) user data that is queried at inference
            time, to the LLM provider, (2) three out of four methods also leak large fractions of
            private training data to the LLM provider while the method that protects private data
            requires a local open LLM, (3) all the methods exhibit lower performance compared
            to three private gradient-based adaptation methods for local open LLMs, and (4) the
            private adaptation methods for closed LLMs incur higher monetary training and
            query costs than running the alternative methods on local open LLMs. This yields
            the conclusion that, to achieve truly privacy-preserving LLM adaptations that yield
            high performance and more privacy at lower costs, taking into account current
            methods and models, one should use open LLMs.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End paper abstract -->




<!-- Paper Key Takeaways -->
<section class="section hero is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Key Takeaways</h2>
        <div class="content has-text-justified">
          <p>
            <b>Adaptations of open LLMs</b> are:
          </p>
          <ol>
            <li><b>more private</b> than closed LLM adaptations since they have significantly fewer possibilities for privacy leakage</li>
            <li><b>more performant</b> than closed LLM adaptations: at the same privacy level, even using much smaller models, we can obtain higher performance with open LLMs due to their ability to support gradient-based adaptation methods</li>
            <li><b>more cost-effective</b> than closed LLM adaptations that incur continuous query costs to an LLM provider</li>
          </ol> 
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End paper Key Takeaways -->




<!-- Paper poster -->
<section class="hero is-small is-light">
  <div class="hero-body">
    <div class="container">
      <h2 class="title">Poster</h2>

      <iframe  src="static/pdfs/OpenLLMS_NeurIPS2024-poster.pdf" width="100%" height="850">
          </iframe>
        
      </div>
    </div>
  </section>
<!--End paper poster -->

<!--BibTex citation -->
  <section class="section" id="BibTeX">
    <div class="container is-max-desktop content">
      <h2 class="title">BibTeX</h2>
      <pre><code>@inproceedings{hanke2024open,
        title     = {Open {LLM}s are Necessary for Current Private Adaptations and Outperform their Closed Alternatives},
        author    = {Vincent Hanke and Tom Blanchard and Franziska Boenisch and Iyiola Emmanuel Olatunji and Michael Backes and Adam Dziedzic},
        booktitle = {Conference on Neural Information Processing Systems (NeurIPS)},
        year = {2024},
}</code></pre>
    </div>
</section>
<!--End BibTex citation -->


  <footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">

          <p>
            This page was built using the <a href="https://github.com/eliahuhorwitz/Academic-project-page-template" target="_blank">Academic Project Page Template</a> which was adopted from the <a href="https://nerfies.github.io" target="_blank">Nerfies</a> project page.
            <br> This website is licensed under a <a rel="license"  href="http://creativecommons.org/licenses/by-sa/4.0/" target="_blank">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>

        </div>
      </div>
    </div>
  </div>
</footer>

<!-- Statcounter tracking code -->
  
<!-- You can add a tracker to track page visits by creating an account at statcounter.com -->

    <!-- End of Statcounter Code -->

  </body>
  </html>